1. Autoencoders learn to copy their inputs to their outputs.


2. multi-layer perceptron 모델은 input node 와 ouput node의 수가 동일하며 하나의 hidden layer를 갖는데, 이 hidden layer의 node 수는 input node보다 `1개`적다. 어떠한 activation fuction 도 설정하지 않은 상황에서 이 모델의 cost function은 MSE로 설정하여 학습을 진행한다고 가장하자. 그리고 input data는 3차원 데이터이다. 이 경우 이 모델은 `principal component analysis 처럼 한 차원 낮은 `2차원`으로 차원을 `축소`하는 역할 을 할 수 있다.

3. 사진의 캡션을 만드는 Recurrent neural network(RNN) 을 모델링 하고자 한다. input은 2D 사진 한 장씩 구성된 데이터 셋이고, output은 여러 단어로 이루어진 문장이 되는 것을 목표로 한다 . 이때 적적한 RNN type 은 `Vector-to-Sequence`이다.

4. RNN을 학습하기 위한 알고리즘으로 Backpropagatin throught time(BPTT)를 사용하려 한다. BPTT를 아래와 같이 4개의 절차로 나누었다고 가정한다면, BPTT의 학습 순서를 왼쪽부터 차례대로 나열하면 다음 과 같다.
    - unrolled net에서 forward pass를 수행하는 것
    - cost function을 사용하여 output sequence를 평가하는 것
    - gradients를 backward로 전파(propagate)하는 것
    - model parameters를 갱신(update)하는 것

5. review를 바탕으로 긍정인지 부정인지에 대한 의미를 파악하는 RNN기반의 모델을 만들려 한다. 
    - (1) 먼저 embedding을 한다.
    - (2) convolutional layer를 거친다.
    - (3) max pooling layer를 거친다.
    - (4) long short-term memory layer를 거친다.
    - (5) 최종적으로 1개의 노드를 갖는 dense layer(또는 fully connected layer)에서 모델의 출력값이 나오게 만든다.
<img src="https://user-images.githubusercontent.com/45276804/101640499-ec988280-3a73-11eb-81d6-280bfcb6a572.png">

    - 이 레이어데 대한 activation function 설정에 관하여, 가장 정확한 의미를 파악할 수 있도록 하는 방법은 logistic sigmoid function을 사용하는 것이다.
    - `ReLU나 leak ReLU는  exploding gradient problem이 있을 수 있으며, softmax 는 binary clasification에 적합하지 않다.`

6. 2014년에 발표된 GoogleNet의 Inception 모듈에서 NxN은 커널사이즈가  N by N을 의미하며, `+1 pooling layer`를 의미한다. 이 때, 이 inception 모듈의 input의 해상도는 7x7인 영상이 들어가고 (a)는 fiter개수가 64, (b) 128개, (c)는 32개 ,(d) 는 32 개인 2D convolution layer라고 할 때, `Depth concat`에서 `concatenatino`을 하고 난 이후에 filter의 총 개수는 `256`개이다.
    <img src = "https://user-images.githubusercontent.com/45276804/101640688-29fd1000-3a74-11eb-9bdf-fab6007afe25.png">
    - 해상도 상관없이 필터의 개수만 묻는 문제이다. 따라서, (a)부터 (d)까지의 모든 필터의 총합은 256이다.

7. Variational autoencoders(VAEs)에 대한 설명은 다음 과 같다.
    - VAEs are probabilistic autoencoders, so their outputs are partly determined by chance, even after training.
    - VAEs are generatvie autoencoders which can generate new instances that look like they were sampled from the trainig set.
    - The encoder of VAE produces a mean u and a standard devitaion b.
    - VAEs are of overcomplete autoencdoer.


